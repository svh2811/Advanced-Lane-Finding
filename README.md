# Advanced-Lane-Finding
Identifying the lane boundaries in a video

---

Aim of this project is to write a software pipeline to identify the lane boundaries in a video.

---

The goals / steps of this project are the following:

* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.
* Apply a distortion correction to raw images.
* Use color transforms, gradients, etc., to create a thresholded binary image.
* Apply a perspective transform to rectify binary image ("birds-eye view").
* Detect lane pixels and fit to find the lane boundary.
* Determine the curvature of the lane and vehicle position with respect to center.
* Warp the detected lane boundaries back onto the original image.
* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.

---

The images for camera calibration are stored in the folder called `data/camera_calibration`.  The images in `data/test_images` are for testing the pipeline on single frames.

### Camera Calibration

#### 1. Computation of the camera matrix and distortion coefficients with an example of a distortion corrected calibration image.

The code for this step is contained in the file `transformation.py` and function `get_camera_calibration_matrix()`.  

I start by preparing "object points", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time I successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.  

![Corners Connected][./examples/chessboard.jpg]

I then used the output `objpoints` and `imgpoints` to compute the camera calibration and distortion coefficients using the `cv2.calibrateCamera()` function.  I applied this distortion correction to the test image using the `cv2.undistort()` function and obtained this result: 

### Pipeline (single images)

#### 1. An example of a distortion-corrected image.

To demonstrate this step, I will describe how I apply the distortion correction to one of the test images like this one:

![Undistored Chessboard Image][./examples/undistort_output.jpg]

![Undistored Highway Image][./examples/undistorted.jpg]

#### 2. Thresholded binary image creation.

I used a combination of color-spaces and gradient thresholds to generate a binary image (thresholding steps at lines # through # in `Advance lane finding pipeline.ipynb` in function `get_thresholded_image()`).  Here's an example of my output for this step.  (note: this is not actually from one of the test images)

Sequence of Image Processing task in pipeline
    1. Color thresholding using LUV color space
    2. Color thresholding using LAB color space
    3. Color thresholding using HSV color space
    4. Combining horizontal and vertical gradients with magnitude threshold
    5. Median blur gradient image
    6. Combine outputs images of steps 1, 2, 3 and 5 

![Thresholding Pipeline][./examples/thresholding-pipeline.png]

#### 3. Describe how (and identify where in your code) you performed a perspective transform and provide an example of a transformed image.

The code for my perspective transform is included in a function called `warp_image()` and `get_perspective_matrices()` both are present in `transformation.py`. The `get_perspective_matrices()` function takes two arrays `src` and `dst` to generate a corresponding transformation matrix. `src` and `dst` are handcrafted to represent an perspective transformation, `src` and `dst` are present in `Advance lane finding pipeline.ipynb`.

```
src = np.float32([ [575, 464], [738, 464], [1005, 694], [290, 694] ])
dst = np.float32([ [180, 0], [540, 0], [540, 720], [180, 720] ])
```

The transformation matrix (which is perspective transform in our case) and an image (which has to be transformed) is passed as an argument to function `warp_image()`.

The example shown above is of an color image however for our problem we use binary-image generated by function `get_thresholded_image()`.  

I verified that my perspective transform was working as expected by drawing the `src` and `dst` points onto a test image and its warped counterpart to verify that the lines appear parallel in the warped image.

![Perspective transform of lane image][./examples/warped_straight_lines.jpg]

#### 4.Lane line detection

Steps of lane line detection:

* If current frame is first video frame:
  + use Sliding Window method
* else
  + use Search from prior
* Either methods would generate a two sets of cor-ordinates one for left lane and one for right lane, these points are feed to `fit_poly()` which attempts to fit a quadratic polynomial curve for each lane 
* ![Lane curves][./examples/color_fit_lines.jpg]

Sliding Window
  1. method `group_lane_pixels_using_sliding_window()` present in file `lane_line.py`
  2. Start by generating histgrom of thresholded-binary-perspective-transformed-image to find two lane centers.
  3. ![Histogram][./examples/histogram.png]
  4. Using calculated lane centers, start a sliding window search from bottom of the image and sliding upwards following white pixels in the image.
  5. ![Sliding window][./examples/sliding-window.png]

Search from prior
  1. method `group_lane_pixels_using_prev_frame()` present in file `lane_line.py`
  2. This method uses the lane points detected in the  previous image frame to narrow down the search region to search lane.
  3. ![Sliding prior][./examples/saving-prior.png]

#### 5. Calculating radius of curvature of the lane and the position of the vehicle with respect to center.

I did this in lines # through # in my code in `my_other_file.py`

#### 6. Provide an example image of your result plotted back down onto the road such that the lane area is identified clearly.

I implemented this step in lines # through # in my code in `yet_another_file.py` in the function `map_lane()`.  Here is an example of my result on a test image:

![alt text][image6]

---

### Pipeline (video)

#### 1. Link to final video output.

Here's a [link to my video result](./output/output_videos/project_video.mp4)

---

### Discussion

#### 1. Briefly discuss any problems / issues you faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?

Here I'll talk about the approach I took, what techniques I used, what worked and why, where the pipeline might fail and how I might improve it if I were going to pursue this project further.  
